{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Convolutional Netoworks and the ACM Heterogenous Graph\n",
    "this is a slightly modified version of the notebook from the DGL tutorial\n",
    "https://docs.dgl.ai/en/0.4.x/tutorials/hetero/1_basics.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ".. currentmodule:: dgl\n",
    "\n",
    "Working with Heterogeneous Graphs\n",
    "=================================\n",
    "\n",
    "**Author**: Quan Gan, `Minjie Wang <https://jermainewang.github.io/>`_, Mufei Li,\n",
    "George Karypis, Zheng Zhang\n",
    "\n",
    "In this tutorial, you learn about:\n",
    "\n",
    "* Examples of heterogenous graph data and typical applications.\n",
    "\n",
    "* Creating and manipulating a heterogenous graph in DGL.\n",
    "\n",
    "* Implementing `Relational-GCN <https://arxiv.org/abs/1703.06103>`_, a popular GNN model,\n",
    "  for heterogenous graph input.\n",
    "\n",
    "* Training a model to solve a node classification task.\n",
    "\n",
    "Heterogeneous graphs, or *heterographs* for short, are graphs that contain\n",
    "different types of nodes and edges. The different types of nodes and edges tend\n",
    "to have different types of attributes that are designed to capture the\n",
    "characteristics of each node and edge type. Within the context of\n",
    "graph neural networks, depending on their complexity, certain node and edge types\n",
    "might need to be modeled with representations that have a different number of dimensions.\n",
    "\n",
    "DGL supports graph neural network computations on such heterogeneous graphs, by\n",
    "using the heterograph class and its associated API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of heterographs\n",
    "-----------------------\n",
    "Many graph datasets represent relationships among various types of entities.\n",
    "This section provides an overview for several graph use-cases that show such relationships \n",
    "and can have their data represented as heterographs.\n",
    "\n",
    "Citation graph \n",
    "~~~~~~~~~~~~~~~\n",
    "The Association for Computing Machinery publishes an `ACM dataset <https://aminer.org/citation>`_ that contains two\n",
    "million papers, their authors, publication venues, and the other papers\n",
    "that were cited. This information can be represented as a heterogeneous graph.\n",
    "\n",
    "The following diagram shows several entities in the ACM dataset and the relationships among them \n",
    "(taken from `Shi et al., 2015 <https://arxiv.org/pdf/1511.04854.pdf>`_).\n",
    "\n",
    ".. figure:: https://data.dgl.ai/tutorial/hetero/acm-example.png# \n",
    "\n",
    "This graph has three types of entities that correspond to papers, authors, and publication venues.\n",
    "It also contains three types of edges that connect the following:\n",
    "\n",
    "* Authors with papers corresponding to *written-by* relationships\n",
    "\n",
    "* Papers with publication venues corresponding to *published-in* relationships\n",
    "\n",
    "* Papers with other papers corresponding to *cited-by* relationships\n",
    "\n",
    "\n",
    "Recommender systems \n",
    "~~~~~~~~~~~~~~~~~~~~ \n",
    "The datasets used in recommender systems often contain\n",
    "interactions between users and items. For example, the data could include the\n",
    "ratings that users have provided to movies. Such interactions can be modeled\n",
    "as heterographs.\n",
    "\n",
    "The nodes in these heterographs will have two types, *users* and *movies*. The edges\n",
    "will correspond to the user-movie interactions. Furthermore, if an interaction is\n",
    "marked with a rating, then each rating value could correspond to a different edge type.\n",
    "The following diagram shows an example of user-item interactions as a heterograph.\n",
    "\n",
    ".. figure:: https://data.dgl.ai/tutorial/hetero/recsys-example.png\n",
    "\n",
    "\n",
    "Knowledge graph \n",
    "~~~~~~~~~~~~~~~~\n",
    "Knowledge graphs are inherently heterogenous. For example, in\n",
    "Wikidata, Barack Obama (item Q76) is an instance of a human, which could be viewed as\n",
    "the entity class, whose spouse (item P26) is Michelle Obama (item Q13133) and\n",
    "occupation (item P106) is politician (item Q82955). The relationships are shown in the following.\n",
    "diagram.\n",
    "\n",
    ".. figure:: https://data.dgl.ai/tutorial/hetero/kg-example.png\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a heterograph in DGL\n",
    "-----------------------------\n",
    "You can create a heterograph in DGL using the :func:`dgl.heterograph` API.\n",
    "The argument to :func:`dgl.heterograph` is a dictionary. The keys are tuples\n",
    "in the form of ``(srctype, edgetype, dsttype)`` specifying the relation name\n",
    "and the two entity types it connects. Such tuples are called *canonical edge\n",
    "types*. The values are data to initialize the graph structures, that is, which\n",
    "nodes the edges actually connect.\n",
    "\n",
    "For instance, the following code creates the user-item interactions heterograph shown earlier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "# Each value of the dictionary is a pair of source and destination arrays.\n",
    "# Nodes are integer IDs starting from zero. Nodes IDs of different types have\n",
    "# separate countings.\n",
    "import dgl\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DGL supports creating a graph from a variety of data sources. The following\n",
    "code creates the same graph as the above.\n",
    "\n",
    "Creating from scipy matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "# Creating from networkx graph\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulating heterograph\n",
    "------------------------\n",
    "You can create a more realistic heterograph using the ACM dataset. To do this, first \n",
    "download the dataset as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__header__', '__version__', '__globals__', 'TvsP', 'PvsA', 'PvsV', 'AvsF', 'VvsC', 'PvsL', 'PvsC', 'A', 'C', 'F', 'L', 'P', 'T', 'V', 'PvsT', 'CNormPvsA', 'RNormPvsA', 'CNormPvsC', 'RNormPvsC', 'CNormPvsT', 'RNormPvsT', 'CNormPvsV', 'RNormPvsV', 'CNormVvsC', 'RNormVvsC', 'CNormAvsF', 'RNormAvsF', 'CNormPvsL', 'RNormPvsL', 'stopwords', 'nPvsT', 'nT', 'CNormnPvsT', 'RNormnPvsT', 'nnPvsT', 'nnT', 'CNormnnPvsT', 'RNormnnPvsT', 'PvsP', 'CNormPvsP', 'RNormPvsP']\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import urllib.request\n",
    "\n",
    "data_url = 'https://data.dgl.ai/dataset/ACM.mat'\n",
    "data_file_path = 'ACM.mat'\n",
    "\n",
    "urllib.request.urlretrieve(data_url, data_file_path)\n",
    "data = scipy.io.loadmat(data_file_path)\n",
    "print(list(data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset stores node information by their types: ``P`` for paper, ``A``\n",
    "for author, ``C`` for conference, ``L`` for subject code, and so on. The relationships\n",
    "are stored as SciPy sparse matrix under key ``XvsY``, where ``X`` and ``Y``\n",
    "could be any of the node type code.\n",
    "\n",
    "The following code prints out some statistics about the paper-author relationships.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csc.csc_matrix'>\n",
      "#Papers: 12499\n",
      "#Authors: 17431\n",
      "#Links: 37055\n"
     ]
    }
   ],
   "source": [
    "print(type(data['PvsA']))\n",
    "print('#Papers:', data['PvsA'].shape[0])\n",
    "print('#Authors:', data['PvsA'].shape[1])\n",
    "print('#Links:', data['PvsA'].nnz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting this SciPy matrix to a heterograph in DGL is straightforward.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a subset of the ACM graph using the paper-author, paper-paper, \n",
    "and paper-subject relationships.  Meanwhile, also add the reverse\n",
    "relationship to prepare for the later sections.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'author': 17431, 'paper': 12499, 'subject': 73},\n",
       "      num_edges={('paper', 'written-by', 'author'): 37055, ('author', 'writing', 'paper'): 37055, ('paper', 'citing', 'paper'): 30789, ('paper', 'cited', 'paper'): 30789, ('paper', 'is-about', 'subject'): 12499, ('subject', 'has', 'paper'): 12499},\n",
       "      metagraph=[('author', 'paper'), ('paper', 'author'), ('paper', 'paper'), ('paper', 'paper'), ('paper', 'subject'), ('subject', 'paper')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = dgl.heterograph({\n",
    "        ('paper', 'written-by', 'author') : data['PvsA'],\n",
    "        ('author', 'writing', 'paper') : data['PvsA'].transpose(),\n",
    "        ('paper', 'citing', 'paper') : data['PvsP'],\n",
    "        ('paper', 'cited', 'paper') : data['PvsP'].transpose(),\n",
    "        ('paper', 'is-about', 'subject') : data['PvsL'],\n",
    "        ('subject', 'has', 'paper') : data['PvsL'].transpose(),\n",
    "    })\n",
    "G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metagraph** (or network schema) is a useful summary of a heterograph.\n",
    "Serving as a template for a heterograph, it tells how many types of objects\n",
    "exist in the network and where the possible links exist.\n",
    "\n",
    "DGL provides easy access to the metagraph, which could be visualized using\n",
    "external tools.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning tasks associated with heterographs\n",
    "-------------------------------------------\n",
    "Some of the typical learning tasks that involve heterographs include:\n",
    "\n",
    "* *Node classification and regression* to predict the class of each node or\n",
    "  estimate a value associated with it.\n",
    "\n",
    "* *Link prediction* to predict if there is an edge of a certain\n",
    "  type between a pair of nodes, or predict which other nodes a particular\n",
    "  node is connected with (and optionally the edge types of such connections).\n",
    "\n",
    "* *Graph classification/regression* to assign an entire\n",
    "  heterograph into one of the target classes or to estimate a numerical\n",
    "  value associated with it.\n",
    "\n",
    "In this tutorial, we designed a simple example for the first task.\n",
    "\n",
    "A semi-supervised node classification example\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "Our goal is to predict the publishing conference of a paper using the ACM\n",
    "academic graph we just created. To further simplify the task, we only focus\n",
    "on papers published in three conferences: *KDD*, *ICML*, and *VLDB*. All\n",
    "the other papers are not labeled, making it a semi-supervised setting.\n",
    "\n",
    "The following code extracts those papers from the raw dataset and prepares \n",
    "the training, validation, testing split.\n",
    "\n",
    "Note:  in this version we look at 4 conferences: SOSP, SODA, Sigcom and VLDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "pvc = data['PvsC'].tocsr()\n",
    "#   sosp = 7\n",
    "#   soda = 5\n",
    "#   sigcom =  9\n",
    "#   vldb = 13\n",
    "c_selected = [7, 5, 9, 13]  \n",
    "\n",
    "p_selected = pvc[:, c_selected].tocoo()\n",
    "# remake 7,5,9,13 labels as 0,1,2,3\n",
    "labels = pvc.indices\n",
    "labels[labels==0] = 13\n",
    "labels[labels==7] = 0\n",
    "labels[labels==1] = 13\n",
    "labels[labels == 5] = 1\n",
    "labels[labels==2] = 13\n",
    "labels[labels == 9]= 2\n",
    "labels[labels == 3] = 13\n",
    "labels[labels == 13] = 3\n",
    "labels = torch.tensor(labels).long()\n",
    "\n",
    "# generate train/val/test split\n",
    "pid = p_selected.row\n",
    "shuffle = np.random.permutation(pid)\n",
    "\n",
    "train_idx = torch.tensor(shuffle[0:1400]).long()\n",
    "val_idx = torch.tensor(shuffle[1400:1500]).long()\n",
    "test_idx = torch.tensor(shuffle[1500:]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332 662 648\n"
     ]
    }
   ],
   "source": [
    "print( len(labels[labels==0]), len(labels[labels==1]), len(labels[labels==2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 719\n"
     ]
    }
   ],
   "source": [
    "print(len(train_idx), len(test_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relational-GCN on heterograph\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "We use `Relational-GCN <https://arxiv.org/abs/1703.06103>`_ to learn the\n",
    "representation of nodes in the graph. Its message-passing equation is as\n",
    "follows:\n",
    "for each message type we will have a fully connected layer of trainable parameters W. Then for \n",
    "for each node and \n",
    "each edge type we compute\n",
    "\n",
    "\\begin{align} \\sum_{j\\in\\mathcal{N}_r(i)} W_r^{(l)}h_j^{(l)} \\end{align}\n",
    "\n",
    "following that sum over each edge type and apply sigma\n",
    "\n",
    "\\begin{align}h_i^{(l+1)} = \\sigma\\left(\\sum_{r\\in \\mathcal{R}}\n",
    "   \\sum_{j\\in\\mathcal{N}_r(i)}W_r^{(l)}h_j^{(l)}\\right)\\end{align}\n",
    "\n",
    "Breaking down the equation, you see that there are two parts in the\n",
    "computation.\n",
    "\n",
    "(i) Message computation and aggregation within each relation $r$\n",
    "\n",
    "(ii) Reduction that merges the results from multiple relationships\n",
    "\n",
    "Following this intuition, perform message passing on a heterograph in\n",
    "two steps.\n",
    "\n",
    "(i) Per-edge-type message passing\n",
    "\n",
    "(ii) Type wise reduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "class HeteroRGCNLayer(nn.Module):\n",
    "    def __init__(self, in_size, out_size, etypes):\n",
    "        super(HeteroRGCNLayer, self).__init__()\n",
    "        # W_r for each relation\n",
    "        self.weight = nn.ModuleDict({\n",
    "                name : nn.Linear(in_size, out_size) for name in etypes\n",
    "            })\n",
    "\n",
    "    def forward(self, G, feat_dict):\n",
    "        # The input is a dictionary of node features for each type\n",
    "        funcs = {}\n",
    "        for srctype, etype, dsttype in G.canonical_etypes:\n",
    "            # Compute W_r * h\n",
    "            Wh = self.weight[etype](feat_dict[srctype])\n",
    "            # Save it in graph for message passing\n",
    "            G.nodes[srctype].data['Wh_%s' % etype] = Wh\n",
    "            # Specify per-relation message passing functions: (message_func, reduce_func).\n",
    "            # Note that the results are saved to the same destination feature 'h', which\n",
    "            # hints the type wise reducer for aggregation.\n",
    "            funcs[etype] = (fn.copy_u('Wh_%s' % etype, 'm'), fn.mean('m', 'h'))\n",
    "        # Trigger message passing of multiple types.\n",
    "        # The first argument is the message passing functions for each relation.\n",
    "        # The second one is the type wise reducer, could be \"sum\", \"max\",\n",
    "        # \"min\", \"mean\", \"stack\"\n",
    "        G.multi_update_all(funcs, 'sum')\n",
    "        # return the updated node feature dictionary\n",
    "        return {ntype : G.nodes[ntype].data['h'] for ntype in G.ntypes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple GNN by stacking two ``HeteroRGCNLayer``. Since the\n",
    "nodes do not have input features, make their embeddings trainable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paper', 'written-by', 'author'),\n",
       " ('author', 'writing', 'paper'),\n",
       " ('paper', 'citing', 'paper'),\n",
       " ('paper', 'cited', 'paper'),\n",
       " ('paper', 'is-about', 'subject'),\n",
       " ('subject', 'has', 'paper')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.canonical_etypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'author': 17431, 'paper': 12499, 'subject': 73},\n",
       "      num_edges={('paper', 'written-by', 'author'): 37055, ('author', 'writing', 'paper'): 37055, ('paper', 'citing', 'paper'): 30789, ('paper', 'cited', 'paper'): 30789, ('paper', 'is-about', 'subject'): 12499, ('subject', 'has', 'paper'): 12499},\n",
       "      metagraph=[('author', 'paper'), ('paper', 'author'), ('paper', 'paper'), ('paper', 'paper'), ('paper', 'subject'), ('subject', 'paper')])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['author', 'paper', 'subject']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.ntypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterDict(\n",
       "    (author): Parameter containing: [torch.FloatTensor of size 17431x10]\n",
       "    (paper): Parameter containing: [torch.FloatTensor of size 12499x10]\n",
       "    (subject): Parameter containing: [torch.FloatTensor of size 73x10]\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dict = {ntype : nn.Parameter(torch.Tensor(G.number_of_nodes(ntype), 10))\n",
    "              for ntype in G.ntypes}\n",
    "for key, embed in embed_dict.items():\n",
    "    nn.init.xavier_uniform_(embed)\n",
    "embed = nn.ParameterDict(embed_dict)\n",
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroRGCN(nn.Module):\n",
    "    def __init__(self, G, in_size, hidden_size, out_size):\n",
    "        super(HeteroRGCN, self).__init__()\n",
    "        # Use trainable node embeddings as featureless inputs.\n",
    "        embed_dict = {ntype : nn.Parameter(torch.Tensor(G.number_of_nodes(ntype), in_size))\n",
    "                      for ntype in G.ntypes}\n",
    "        for key, embed in embed_dict.items():\n",
    "            nn.init.xavier_uniform_(embed)\n",
    "        self.embed = nn.ParameterDict(embed_dict)\n",
    "        # create layers\n",
    "        self.layer1 = HeteroRGCNLayer(in_size, hidden_size, G.etypes)\n",
    "        self.layer2 = HeteroRGCNLayer(hidden_size, out_size, G.etypes)\n",
    "\n",
    "    def forward(self, G):\n",
    "        h_dict = self.layer1(G, self.embed)\n",
    "        h_dict = {k : F.leaky_relu(h) for k, h in h_dict.items()}\n",
    "        h_dict = self.layer2(G, h_dict)\n",
    "        # get paper logits\n",
    "        return h_dict['paper']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate\n",
    "~~~~~~~~~~~~~~~~~~\n",
    "Train and evaluate this network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1.4772, Train Acc 0.2371, Val Acc 0.2300 (Best 0.2300), Test Acc 0.2281 (Best 0.2281)\n",
      "Loss 1.2481, Train Acc 0.6450, Val Acc 0.5300 (Best 0.5300), Test Acc 0.5410 (Best 0.5410)\n",
      "Loss 1.0722, Train Acc 0.7607, Val Acc 0.5800 (Best 0.5800), Test Acc 0.6203 (Best 0.6203)\n",
      "Loss 0.8221, Train Acc 0.8436, Val Acc 0.7400 (Best 0.7500), Test Acc 0.7955 (Best 0.7747)\n",
      "Loss 0.5720, Train Acc 0.8893, Val Acc 0.8100 (Best 0.8100), Test Acc 0.8150 (Best 0.8150)\n",
      "Loss 0.3809, Train Acc 0.9586, Val Acc 0.8600 (Best 0.8600), Test Acc 0.8428 (Best 0.8428)\n",
      "Loss 0.2482, Train Acc 0.9857, Val Acc 0.8700 (Best 0.8700), Test Acc 0.8707 (Best 0.8554)\n",
      "Loss 0.1638, Train Acc 0.9929, Val Acc 0.8500 (Best 0.8700), Test Acc 0.8790 (Best 0.8554)\n",
      "Loss 0.1139, Train Acc 0.9950, Val Acc 0.8800 (Best 0.8800), Test Acc 0.8971 (Best 0.8971)\n",
      "Loss 0.0848, Train Acc 0.9964, Val Acc 0.8900 (Best 0.8900), Test Acc 0.9068 (Best 0.8985)\n",
      "Loss 0.0661, Train Acc 0.9986, Val Acc 0.8900 (Best 0.8900), Test Acc 0.9068 (Best 0.8985)\n",
      "Loss 0.0535, Train Acc 0.9993, Val Acc 0.8900 (Best 0.8900), Test Acc 0.8985 (Best 0.8985)\n",
      "Loss 0.0450, Train Acc 0.9993, Val Acc 0.8900 (Best 0.8900), Test Acc 0.8985 (Best 0.8985)\n",
      "Loss 0.0385, Train Acc 1.0000, Val Acc 0.8800 (Best 0.8900), Test Acc 0.9026 (Best 0.8985)\n",
      "Loss 0.0335, Train Acc 1.0000, Val Acc 0.8800 (Best 0.8900), Test Acc 0.8999 (Best 0.8985)\n",
      "Loss 0.0298, Train Acc 1.0000, Val Acc 0.8800 (Best 0.8900), Test Acc 0.8887 (Best 0.8985)\n",
      "Loss 0.0270, Train Acc 1.0000, Val Acc 0.8600 (Best 0.8900), Test Acc 0.8790 (Best 0.8985)\n",
      "Loss 0.0247, Train Acc 1.0000, Val Acc 0.8600 (Best 0.8900), Test Acc 0.8790 (Best 0.8985)\n",
      "Loss 0.0230, Train Acc 1.0000, Val Acc 0.8600 (Best 0.8900), Test Acc 0.8748 (Best 0.8985)\n",
      "Loss 0.0216, Train Acc 1.0000, Val Acc 0.8600 (Best 0.8900), Test Acc 0.8734 (Best 0.8985)\n"
     ]
    }
   ],
   "source": [
    "# Create the model. The output has four logits for four classes.\n",
    "model = HeteroRGCN(G, 10, 10, 4)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "best_val_acc = 0\n",
    "best_test_acc = 0\n",
    "\n",
    "for epoch in range(100):\n",
    "    logits = model(G)\n",
    "    # The loss is computed only for labeled nodes.\n",
    "    loss = F.cross_entropy(logits[train_idx], labels[train_idx])\n",
    "\n",
    "    pred = logits.argmax(1)\n",
    "    train_acc = (pred[train_idx] == labels[train_idx]).float().mean()\n",
    "    val_acc = (pred[val_idx] == labels[val_idx]).float().mean()\n",
    "    test_acc = (pred[test_idx] == labels[test_idx]).float().mean()\n",
    "\n",
    "    if best_val_acc < val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_test_acc = test_acc\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print('Loss %.4f, Train Acc %.4f, Val Acc %.4f (Best %.4f), Test Acc %.4f (Best %.4f)' % (\n",
    "            loss.item(),\n",
    "            train_acc.item(),\n",
    "            val_acc.item(),\n",
    "            best_val_acc.item(),\n",
    "            test_acc.item(),\n",
    "            best_test_acc.item(),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8707)\n"
     ]
    }
   ],
   "source": [
    "logits = model(G)\n",
    "pred = logits.argmax(1)\n",
    "test_acc = (pred[test_idx] == labels[test_idx]).float().mean()\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array(['KDD'], dtype='<U3')]\n",
      " [array(['SIGMOD'], dtype='<U6')]\n",
      " [array(['WWW'], dtype='<U3')]\n",
      " [array(['SIGIR'], dtype='<U5')]\n",
      " [array(['CIKM'], dtype='<U4')]\n",
      " [array(['SODA'], dtype='<U4')]\n",
      " [array(['STOC'], dtype='<U4')]\n",
      " [array(['SOSP'], dtype='<U4')]\n",
      " [array(['SPAA'], dtype='<U4')]\n",
      " [array(['SIGCOMM'], dtype='<U7')]\n",
      " [array(['MobiCOMM'], dtype='<U8')]\n",
      " [array(['ICML'], dtype='<U4')]\n",
      " [array(['COLT'], dtype='<U4')]\n",
      " [array(['VLDB'], dtype='<U4')]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data['C'][:]\n",
    "print(x)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try this:\n",
    "   sosp = 7\n",
    "   soda = 5\n",
    "   sigcom =  9\n",
    "   vldb = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = np.zeros([4,4])\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[200.,   0.,   0.,   0.],\n",
       "       [  0., 421.,   0.,   0.],\n",
       "       [  0.,   0., 415.,   0.],\n",
       "       [  0.,   0.,   0., 364.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = np.zeros([4,4])\n",
    "for i in train_idx:\n",
    "    if labels[i] == 0:\n",
    "        mat[0, pred[i]]+=1\n",
    "    if labels[i] == 1:\n",
    "        mat[1, pred[i]]+=1\n",
    "    if labels[i] == 2:\n",
    "        mat[2, pred[i]]+=1\n",
    "    if labels[i] == 3:\n",
    "        mat[3, pred[i]]+=1\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 92.,   2.,  12.,   8.],\n",
       "       [  2., 206.,   1.,   5.],\n",
       "       [  8.,  28., 161.,  10.],\n",
       "       [  1.,  16.,   0., 167.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = np.zeros([4,4])\n",
    "for i in test_idx:\n",
    "    if labels[i] == 0:\n",
    "        mat[0, pred[i]]+=1\n",
    "    if labels[i] == 1:\n",
    "        mat[1, pred[i]]+=1\n",
    "    if labels[i] == 2:\n",
    "        mat[2, pred[i]]+=1\n",
    "    if labels[i] == 3:\n",
    "        mat[3, pred[i]]+=1\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[81.,  2., 11.,  7.],\n",
       "       [ 1., 96.,  0.,  2.],\n",
       "       [ 4., 14., 78.,  5.],\n",
       "       [ 1.,  9.,  0., 91.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    tot = sum(mat[i,:])\n",
    "    mat[i,:] = np.round(100.0*mat[i,:]/tot,0)\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sosp</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>soda</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sigcom</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vldb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1     2     3\n",
       "sosp    81.0   2.0  11.0   7.0\n",
       "soda     1.0  96.0   0.0   2.0\n",
       "sigcom   4.0  14.0  78.0   5.0\n",
       "vldb     1.0   9.0   0.0  91.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(mat, index =['sosp', 'soda', 'sigcom','vldb'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's next?\n",
    "------------\n",
    "* Check out our full implementation in PyTorch\n",
    "  `here <https://github.com/dmlc/dgl/tree/master/examples/pytorch/rgcn-hetero>`_.\n",
    "\n",
    "* We also provide the following model examples:\n",
    "\n",
    "  * `Graph Convolutional Matrix Completion <https://arxiv.org/abs/1706.02263>_`,\n",
    "    which we implement in MXNet\n",
    "    `here <https://github.com/dmlc/dgl/tree/v0.4.0/examples/mxnet/gcmc>`_.\n",
    "\n",
    "  * `Heterogeneous Graph Attention Network <https://arxiv.org/abs/1903.07293>`_\n",
    "    requires transforming a heterograph into a homogeneous graph according to\n",
    "    a given metapath (i.e. a path template consisting of edge types).  We\n",
    "    provide :func:`dgl.transform.metapath_reachable_graph` to do this.  See full\n",
    "    implementation\n",
    "    `here <https://github.com/dmlc/dgl/tree/master/examples/pytorch/han>`_.\n",
    "\n",
    "  * `Metapath2vec <https://dl.acm.org/citation.cfm?id=3098036>`_ requires\n",
    "    generating random walk paths according to a given metapath.  Please\n",
    "    refer to the full metapath2vec implementation\n",
    "    `here <https://github.com/dmlc/dgl/tree/master/examples/pytorch/metapath2vec>`_.\n",
    "\n",
    "* :doc:`Full heterograph API reference <../../api/python/heterograph>`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
